{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "API_KEY = '4e1f86110caa98dbcd444fdf6229e002'\n",
    "FORM_ID = '250216539146152'\n",
    "\n",
    "def get_field_map():\n",
    "    url = f'https://api.jotform.com/form/{FORM_ID}/questions?apiKey={API_KEY}'\n",
    "    response = requests.get(url)\n",
    "    questions = response.json()['content']\n",
    "    return {str(qid): qdata['text'] for qid, qdata in questions.items()}\n",
    "\n",
    "def fetch_jotform_json():\n",
    "    all_submissions = []\n",
    "    offset = 0\n",
    "    while True:\n",
    "        url = f'https://api.jotform.com/form/{FORM_ID}/submissions?apiKey={API_KEY}&limit=1000&offset={offset}'\n",
    "        data = requests.get(url).json()\n",
    "        batch = data['content']\n",
    "        if not batch:\n",
    "            break\n",
    "        all_submissions.extend(batch)\n",
    "        offset += 1000\n",
    "    return all_submissions\n",
    "\n",
    "def clean_jotform_data(submissions, field_map):\n",
    "    flat_list = []\n",
    "    for submission in submissions:\n",
    "        flat = {}\n",
    "        for k, v in submission['answers'].items():\n",
    "            label = field_map.get(k, k)\n",
    "            ans = v.get('answer', None)\n",
    "            if isinstance(ans, dict):\n",
    "                for subk, subv in ans.items():\n",
    "                    flat[f\"{label}_{subk}\"] = subv\n",
    "            else:\n",
    "                flat[label] = ans\n",
    "        flat_list.append(flat)\n",
    "    df = pd.DataFrame(flat_list)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fech and display the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "field_map = get_field_map()\n",
    "submissions = fetch_jotform_json()\n",
    "df = clean_jotform_data(submissions, field_map)\n",
    "df.head()  # Show the first few rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Edit dta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show all columns\n",
    "df.columns\n",
    "\n",
    "# Filter by a specific field\n",
    "df[df['Your Question Text'] == 'Some Value']\n",
    "\n",
    "# Edit a value\n",
    "df.at[0, 'Your Question Text'] = 'New Value'\n",
    "\n",
    "# Save your edits\n",
    "df.to_csv('edited_jotform_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rename columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have already loaded your DataFrame as df\n",
    "\n",
    "# List of your desired short keys in order\n",
    "short_keys = [\n",
    "    \"implantacion_registro\",\n",
    "    \"medico_implante_otro\",\n",
    "    \"institucion_implante_otro\",\n",
    "    \"ciudad_implante_otro\",\n",
    "    \"implante_dia\",\n",
    "    \"implante_mes\",\n",
    "    \"implante_ano\",\n",
    "    \"fecha_implante\",\n",
    "    \"page_break\",\n",
    "    \"info_paciente\",\n",
    "    \"paciente_nombre\",\n",
    "    \"paciente_cedula\",\n",
    "    \"nacimiento_dia\",\n",
    "    \"nacimiento_mes\",\n",
    "    \"nacimiento_ano\",\n",
    "    \"fecha_nacimiento\",\n",
    "    \"paciente_telefono\",\n",
    "    \"info_implante\",\n",
    "    \"anexo_garantia\",\n",
    "    \"serial_marcapasos\",\n",
    "    \"tipo_dispositivo\",\n",
    "    \"indicacion\",\n",
    "    \"confirmacion\",\n",
    "    \"submit\",\n",
    "    \"tecnico_asistente\",\n",
    "    \"tecnico_asistente_otro\",\n",
    "    \"medico_implante\",\n",
    "    \"institucion_implante\",\n",
    "    \"ciudad_implante\",\n",
    "    \"estado_implante\",\n",
    "    \"certifico_veracidad\",\n",
    "    \"certifico_veracidad_otro\"\n",
    "]\n",
    "\n",
    "# Assign the new column names\n",
    "df.columns = short_keys\n",
    "\n",
    "# Remove columns by name\n",
    "df = df.drop(['submit', 'page_break', 'confirmacion'], axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, col in enumerate(df.columns):\n",
    "    print(f\"{i}: {col}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clean medico_implante_otro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "import re\n",
    "from rapidfuzz import process, fuzz\n",
    "\n",
    "# 1. Improved normalization function\n",
    "def normalize_name(name):\n",
    "    if not isinstance(name, str):\n",
    "        return ''\n",
    "    # Remove accents\n",
    "    name = unicodedata.normalize('NFKD', name).encode('ASCII', 'ignore').decode('utf-8')\n",
    "    # Lowercase\n",
    "    name = name.lower()\n",
    "    # Remove common prefixes (dr, dra, etc.)\n",
    "    name = re.sub(r'\\bdr\\.?\\b|\\bdra\\.?\\b', '', name)\n",
    "    # Remove leading/trailing punctuation and spaces\n",
    "    name = re.sub(r'^[^a-zA-Z0-9]+', '', name)  # Remove leading non-alphanum\n",
    "    name = re.sub(r'[^a-zA-Z0-9]+$', '', name)  # Remove trailing non-alphanum\n",
    "    # Remove extra spaces between words\n",
    "    name = re.sub(r'\\s+', ' ', name)\n",
    "    # Capitalize first letter of each word\n",
    "    name = name.title()\n",
    "    # Final strip to remove any leading/trailing spaces\n",
    "    name = name.strip()\n",
    "    return name\n",
    "\n",
    "df['medico_implante_otro_normalized'] = df['medico_implante_otro'].apply(normalize_name)\n",
    "\n",
    "# 2. Get unique, non-empty normalized names\n",
    "unique_names = df['medico_implante_otro_normalized'].dropna().unique()\n",
    "unique_names = [name for name in unique_names if name]\n",
    "\n",
    "print(\"All unique normalized names:\")\n",
    "for i, name in enumerate(unique_names, 1):\n",
    "    print(f\"{i}: {name}\")\n",
    "\n",
    "# 3. Fuzzy match similar names (threshold 90%)\n",
    "print(\"\\nGroups of similar names (fuzzy match >= 90%):\")\n",
    "seen = set()\n",
    "for name in unique_names:\n",
    "    if name in seen:\n",
    "        continue\n",
    "    matches = process.extract(name, unique_names, scorer=fuzz.ratio, limit=None)\n",
    "    similar = [match for match, score, _ in matches if score >= 90]\n",
    "    if len(similar) > 1:\n",
    "        print(f\"Group: {similar}\")\n",
    "        seen.update(similar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure both columns are strings (to avoid NaN issues)\n",
    "df['medico_implante'] = df['medico_implante'].fillna('').astype(str).str.strip()\n",
    "df['medico_implante_otro_normalized'] = df['medico_implante_otro_normalized'].fillna('').astype(str).str.strip()\n",
    "\n",
    "# Create the merged column\n",
    "df['medico_implante_final'] = df['medico_implante']\n",
    "df.loc[df['medico_implante_final'] == '', 'medico_implante_final'] = df['medico_implante_otro_normalized']\n",
    "\n",
    "df = df.drop(['medico_implante', 'medico_implante_otro', 'medico_implante_otro_normalized'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to datetime if not already\n",
    "df['fecha_implante'] = pd.to_datetime(df['fecha_implante'], errors='coerce')\n",
    "\n",
    "# Format as YYYY-MM-DD string (no time)\n",
    "df['fecha_implante'] = df['fecha_implante'].dt.strftime('%Y-%m-%d')\n",
    "\n",
    "# Now save to CSV\n",
    "df.to_csv('cleaned_jotform_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove accents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "\n",
    "def remove_accents(val):\n",
    "    if isinstance(val, str):\n",
    "        return unicodedata.normalize('NFKD', val).encode('ASCII', 'ignore').decode('utf-8')\n",
    "    return val\n",
    "\n",
    "# Remove accents from all fields in the DataFrame\n",
    "df = df.applymap(remove_accents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display installations by date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import seaborn as sns\n",
    "# import matplotlib.pyplot as plt\n",
    "# import calendar\n",
    "# import numpy as np\n",
    "\n",
    "# # Ensure fecha_implante is datetime\n",
    "# df['fecha_implante'] = pd.to_datetime(df['fecha_implante'], errors='coerce')\n",
    "\n",
    "# # Group by week (Monday as the start of the week)\n",
    "# df['week_start'] = df['fecha_implante'].dt.to_period('W').apply(lambda r: r.start_time)\n",
    "# df['week_num'] = df['week_start'].dt.isocalendar().week\n",
    "# df['year'] = df['week_start'].dt.year\n",
    "# df['month'] = df['week_start'].dt.month\n",
    "\n",
    "# # Get counts by week\n",
    "# counts_by_week = df.groupby(['year', 'week_num', 'month'])['fecha_implante'].count().reset_index()\n",
    "# counts_by_week = counts_by_week.sort_values(['year', 'week_num'])\n",
    "\n",
    "# # Prepare x labels: \"Wk XX\"\n",
    "# x_labels = [f\"Wk {wk}\" for wk in counts_by_week['week_num']]\n",
    "\n",
    "# plt.figure(figsize=(16,7))\n",
    "# bars = sns.barplot(x=x_labels, y=counts_by_week['fecha_implante'], palette='Blues')\n",
    "\n",
    "# # Annotate each bar with the count value\n",
    "# for i, count in enumerate(counts_by_week['fecha_implante']):\n",
    "#     bars.text(i, count + 0.1, str(count), ha='center', va='bottom', fontsize=9, fontweight='bold')\n",
    "\n",
    "# plt.xlabel('Semana del Año')\n",
    "# plt.ylabel('Cantidad de Implantes')\n",
    "# plt.title('Cantidad de Implantes por Semana')\n",
    "\n",
    "# # Add month labels only once per month, centered under the corresponding weeks\n",
    "# months = counts_by_week['month'].values\n",
    "# month_names = [calendar.month_name[m] for m in months]\n",
    "# unique_months = []\n",
    "# month_positions = []\n",
    "# i = 0\n",
    "# while i < len(months):\n",
    "#     m = months[i]\n",
    "#     name = calendar.month_name[m]\n",
    "#     # Find the range of this month\n",
    "#     start = i\n",
    "#     while i + 1 < len(months) and months[i + 1] == m:\n",
    "#         i += 1\n",
    "#     end = i\n",
    "#     center = (start + end) / 2\n",
    "#     unique_months.append(name)\n",
    "#     month_positions.append(center)\n",
    "#     i += 1\n",
    "\n",
    "# # Add the month names below the x-axis\n",
    "# ymin = -max(counts_by_week['fecha_implante']) * 0.08\n",
    "# for pos, name in zip(month_positions, unique_months):\n",
    "#     plt.text(pos, ymin, name, ha='center', va='top', fontsize=12, fontweight='bold', color='navy')\n",
    "\n",
    "# plt.xticks(rotation=0)\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['institucion_implante_otro', 'ciudad_implante_otro', 'fecha_implante', 'paciente_nombre', 'paciente_cedula', 'fecha_nacimiento', 'paciente_telefono', 'anexo_garantia', 'serial_marcapasos', 'tipo_dispositivo', 'indicacion', 'tecnico_asistente', 'tecnico_asistente_otro', 'institucion_implante', 'ciudad_implante', 'estado_implante', 'certifico_veracidad', 'certifico_veracidad_otro', 'medico_implante_final']\n"
     ]
    }
   ],
   "source": [
    "#Remove columns\n",
    "\n",
    "columns_to_drop = [\n",
    "    'implante_dia', 'implante_mes', 'implante_ano', 'info_paciente',\n",
    "    'implantacion_registro', 'nacimiento_dia', 'nacimiento_mes', 'nacimiento_ano',\n",
    "    'info_implante', 'mes_implante', 'week_start', 'week_num', 'year', \"month\"\n",
    "]\n",
    "\n",
    "df = df.drop(columns=columns_to_drop, errors='ignore')\n",
    "\n",
    "# Display the remaining columns to confirm\n",
    "print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['institucion_implante', 'institucion_implante_otro', 'ciudad_implante', 'ciudad_implante_otro', 'estado_implante', 'fecha_implante', 'paciente_nombre', 'paciente_cedula', 'fecha_nacimiento', 'paciente_telefono', 'tipo_dispositivo', 'serial_marcapasos', 'indicacion', 'anexo_garantia', 'medico_implante_final', 'tecnico_asistente', 'tecnico_asistente_otro', 'certifico_veracidad', 'certifico_veracidad_otro']\n"
     ]
    }
   ],
   "source": [
    "#Reorder columns\n",
    "\n",
    "desired_order = [\n",
    "    'institucion_implante',\n",
    "    'institucion_implante_otro',\n",
    "    'ciudad_implante',\n",
    "    'ciudad_implante_otro',\n",
    "    'estado_implante',\n",
    "    'fecha_implante',\n",
    "    'paciente_nombre',\n",
    "    'paciente_cedula',\n",
    "    'fecha_nacimiento',\n",
    "    'paciente_telefono',\n",
    "    'tipo_dispositivo',\n",
    "    'serial_marcapasos',\n",
    "    'indicacion',\n",
    "    'anexo_garantia',\n",
    "    'medico_implante_final',\n",
    "    'tecnico_asistente',\n",
    "    'tecnico_asistente_otro',\n",
    "    'certifico_veracidad',\n",
    "    'certifico_veracidad_otro'\n",
    "]\n",
    "\n",
    "# Reorder the DataFrame columns\n",
    "df = df[desired_order]\n",
    "\n",
    "# Display the new column order to confirm\n",
    "print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the DataFrame to a CSV file\n",
    "df.to_csv('cleaned_jotform_data.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
